# -*- coding: utf-8 -*-
"""gradient_descent (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pg-0MkC1xxDAcOs2cW35fO0CZpxRm7B3
"""

import numpy as np
import matplotlib.pyplot as plt

def gradient_descent(x, y, iterations=1000, rate=0.01):
    x = np.array(x)
    y = np.array(y)
    m_curr = b_curr = 0
    n = len(x)

    plt.figure(figsize=(10, 6))
    plt.scatter(x, y, color='red', marker='+', linewidth=5)

    for i in range(iterations):
        y_predicted = m_curr * x + b_curr
        md = -(2/n) * sum(x * (y - y_predicted))
        bd = -(2/n) * sum(y - y_predicted)
        m_curr = m_curr - rate * md
        b_curr = b_curr - rate * bd

        # plot only every 500th iteration for visibility
        if i % 500 == 0:
            plt.plot(x, y_predicted, label=f'Iter {i}', alpha=0.5)

    # Plot final prediction
    plt.plot(x, m_curr * x + b_curr, color='blue', label='Final Line', linewidth=2)
    plt.legend()
    plt.title("Gradient Descent Linear Regression")
    plt.xlabel("x")
    plt.ylabel("y")
    plt.grid(True)
    plt.show()

    return m_curr, b_curr

x = [1, 2, 3, 4, 5]
y = [5, 7, 9, 11, 13]

m, b = gradient_descent(x, y)
print(f"Final equation: y = {m:.2f}x + {b:.2f}")