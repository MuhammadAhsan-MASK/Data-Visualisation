# -*- coding: utf-8 -*-
"""PCA_tutorial_digits.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BYZdMVDwheWys7o4w9SigXLTYSZZC5r3

<h2 align='center'>Principal Component Analysis Tutorial</h2>
"""

from sklearn.datasets import load_digits
import pandas as pd

dataset = load_digits()
dataset.keys()

dataset.data.shape

dataset.data[0]

dataset.data[0].reshape(8,8)

# Commented out IPython magic to ensure Python compatibility.
from matplotlib import pyplot as plt
# %matplotlib inline
plt.gray()
plt.matshow(dataset.data[0].reshape(8,8))

plt.matshow(dataset.data[9].reshape(8,8))

dataset.target[:5]

df = pd.DataFrame(dataset.data, columns=dataset.feature_names)
df

dataset.target

df.describe()

X = df
y = dataset.target

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)
model.score(X_test, y_test)

"""<h3>Use PCA to reduce dimensions</h3>"""

X

"""<h4>Use components such that 95% of variance is retained</h4>"""

from sklearn.decomposition import PCA

pca = PCA(0.95)
X_pca = pca.fit_transform(X)
X_pca.shape

pca.explained_variance_ratio_

pca.n_components_

"""**PCA created 29 components out of 64 original columns**"""

X_pca

X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=30)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=1000)
model.fit(X_train_pca, y_train)
model.score(X_test_pca, y_test)

"""**Let's now select only two components**"""

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)
X_pca.shape

X_pca

pca.explained_variance_ratio_

"""**You can see that both combined retains 0.14+0.13=0.27 or 27% of important feature information**"""

X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=30)

model = LogisticRegression(max_iter=1000)
model.fit(X_train_pca, y_train)
model.score(X_test_pca, y_test)

"""We get less accuancy (~60%) as using only 2 components did not retain much of the feature information. However in real life you will find many cases where using 2 or few PCA components can still give you a pretty good accuracy"""